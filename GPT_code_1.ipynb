{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ap_key='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Authorization: ap_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 4) (1815284775.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [5], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    -d '{\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 4)\n"
     ]
    }
   ],
   "source": [
    "curl https://api.openai.com/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer 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\" \\\n",
    "  -d '{\n",
    "     \"model\": \"gpt-4\",\n",
    "     \"messages\": [{\"role\": \"user\", \"content\": \"Say this is a test!\"}],\n",
    "     \"temperature\": 0.7\n",
    "   }'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-ACZcHjnusQgzsfmJlhkB6dbyYUJLp\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1727560209,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"This is a test! How can I assist you today?\",\n",
      "        \"refusal\": null\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 13,\n",
      "    \"completion_tokens\": 12,\n",
      "    \"total_tokens\": 25,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"system_fingerprint\": \"fp_f85bea6784\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the curl command as a list of arguments\n",
    "curl_command = [\n",
    "    \"curl\", \"https://api.openai.com/v1/chat/completions\",\n",
    "    \"-H\", \"Content-Type: application/json\",\n",
    "    \"-H\", \"Authorization: Bearer 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\",\n",
    "    \"-d\", '{\"model\": \"gpt-4o-mini-2024-07-18\", \"messages\": [{\"role\": \"user\", \"content\": \"Say this is a test!\"}], \"temperature\": 0.7}'\n",
    "]\n",
    "\n",
    "# Run the curl command\n",
    "result = subprocess.run(curl_command, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18) Postings | Handshake Skip to content Jobs Search Saved 1 SA Home Feed New Inbox 17 Jobs Events People New Employers Career center NJIT collections Location Onsite/remote Full-time job Internship Part-time All filters 33.3K jobs found Relevance Results Loaded Merck & Co., Inc. Pharmaceuticals 2025 University Recruiting - IT Emerging Talent Summer Intern Program Internship ∙ Jun 2–Aug 11 Rahway, NJ ∙ 4d ago Under Armour Fashion Summer 2025 Internship, Enterprise Data Management $20–30/hr ∙ Internship ∙ Jun 2–Aug 29 Remote ∙ 3d ago Coaction Specialty Insurance Insurance IT Internship - Data $20–30/hr ∙ Internship ∙ Jun 3–Aug 7 Morristown, NJ ∙ 5d ago Enova International Internet & Software Analytics Intern 2025 (Hybrid) $30–40/hr ∙ Internship ∙ Jun 17–Aug 22 Chicago, IL ∙ New Nissan North America Automotive Data Scientist Intern - Summer 2025 - Farmington Hills, MI Internship ∙ May 12–Aug 1 Farmington Hills, MI ∙ 4d ago Seagate Technology Electronic & Computer Hardware Intern - Data Analyst $30–40/hr ∙ Internship ∙ May 19–Aug 8 Minneapolis, MN ∙ 2wk ago Ibotta Internet & Software (#R-101567) Machine Learning Intern $30–40/hr ∙ Internship ∙ May 19–Aug 29 Denver, CO ∙ 1wk ago fundae Software Inc Internet & Software Co-op - GEN AI, AL and Data Analytics Co-op ∙ May 1–Nov 1 Remote ∙ 5mo ago STEALTH Internet & Software AI Intern $50–60/hr ∙ Internship Remote ∙ 1mo ago Goldman Sachs Investment Banking 2025 Engineering Summer Analyst Program Internship ∙ Jun 9–Aug 15 Various US locations ∙ 2mo ago Dow Jones & Co. Journalism, Media & Publishing Summer 2025 Internship - Data Analyst $25/hr ∙ Internship ∙ Jun 9–Aug 15 New York, NY ∙ New Smart Rewards Inc Information Technology AI and ML Intern Unpaid ∙ Internship ∙ Sep 25–Mar 25 Remote ∙ 3d ago TransUnion, LLC Other Industries Data Science Internship $22–40/hr ∙ Internship Chicago, IL + 1 ∙ 3d ago ADM Food & Beverage Data Scientist Intern Internship ∙ May 19–Aug 8 Erlanger, KY ∙ 3wk ago Total Wine & More Retail Stores Data Science Summer Internship Program $25/hr ∙ Internship ∙ Jun 2–Aug 15 Bethesda, MD ∙ 1wk ago NielsenIQ Research NIQ Data Science Internship $23–25/hr ∙ Internship ∙ Jun 9–Aug 15 Chicago, IL ∙ 2wk ago Amazon Internet & Software Business Intelligence Engineer Summer Internship – 2025 (US) $35.63–79.62/hr ∙ Internship ∙ May 5–Aug 29 Various US locations ∙ 1mo ago NXP Semiconductors Electronic & Computer Hardware Internships in Data Science - Summer 2025 Internship ∙ May 19–Aug 8 Chandler, AZ + 1 ∙ 3wk ago Amazon Internet & Software Data Engineer Summer Internship – 2025 (US) $43.85–88.94/hr ∙ Internship ∙ May 5–Aug 29 Various US locations ∙ 1mo ago Garmin Electronic & Computer Hardware Data Engineer Intern Internship Olathe, KS ∙ 1wk ago Mutual of Omaha Insurance Summer 2025 Graduate Data Science Intern $30–39/hr ∙ Internship ∙ May 19–Aug 8 Remote ∙ 3wk ago JPMorgan Chase & Co. Financial Services 2025 AI & Data Science Associate Program - Summer Associate $135–155K/yr ∙ Internship ∙ Jun 9–Aug 8 New York, NY + 3 ∙ 2mo ago STEALTH Internet & Software Data Science Intern $50–60/hr ∙ Internship Remote ∙ 1mo ago Atmosfy, Inc Internet & Software Data Science Intern $40–50/hr ∙ Internship Remote ∙ 3mo ago Rangam Consultants Inc. Staffing & Recruiting Data Analyst Intern $54–82K/yr ∙ Internship ∙ May 1–Aug 1 McLean, VA ∙ 2wk ago 1 / 1332 Dow Jones & Co. Journalism, Media & Publishing Summer 2025 Internship - Data Analyst Posted 2 days ago ∙ Applied Did you apply to this job? You started an application on the employer’s website. View application Yes No At a glance $25/hr Hybrid, based in New York, NY Work in person for part of the week, from the location Internship Full-time ∙ From June 9 to August 15 US work authorization required Open to candidates with OPT/CPT Summer 2025 Internship - Data Analyst Application Deadline: November 15, 2024 We encourage you to submit your application as soon as you can as internship applications are reviewed on a rolling basis. Internship Dates & Details: June 9, 2025 - August 15, 2025 (You must be available to work during this period) About our Organization: Dow Jones is a global provider of news and business information, delivering content to consumers and organizations around the world across multiple formats, including print, digital, mobile and live events. Dow Jones has produced unrivaled quality content for more than 130 years and today has one of the world's largest news-gathering operations globally. It is home to leading publications and products including the flagship Wall Street Journal, America's largest newspaper by paid circulation; Barron's, MarketWatch, Mansion Global, Financial News, Investor's Business Daily, Factiva, Dow Jones Risk & Compliance, Dow Jones Newswires, OPIS and Chemical Market Analytics. Dow Jones is a division of News Corp (Nasdaq: NWS, NWSA; ASX: NWS, NWSLV). About the Role: You will be a part of our Insights and Solutions teams. The Data Analyst intern will be an integral member of the Dow Jones Data Management team in either our New York City office. You will support projects of data insights, engineering, and transformation strategy, which in turn supports the larger strategic goals at Dow Jones. This role would support either the Consumer or Professional Information side of the business, which includes Factiva, Risk & Compliance, WSJ, Barron’s, MarketWatch and more; but may also include exposure to other areas of the business, such as advertising. This role is hybrid, based in our New York City office. You Will: Assist with customer-facing report deliveries, both existing and ad hoc requests Interpret trends from data and work closely with stakeholders to enable them to understand the dynamics behind the data Contribute to the development of daily, weekly, monthly, and quarterly dashboards and assist in building new dashboards using Adobe, Tableau, Google Analytics, or other approved data visualization tools leveraging our own internal data lakes Apply fundamental skills in quantitative analysis, data exploration, and the presentation of data to see beyond the numbers and understand how our users interact with our products Support the company’s use of state-of-the art technology end-to-end; from data pipelines, to analysis, models, algorithms and visualization You Have: Completed at least 2 years toward your Bachelor’s degree in a quantitative subject (Statistics, Engineering, Economics, etc.) Exposure to data analysis and problem solving with large amounts of diverse data Basic fluency in SQL, Python or knowledge of relational databases and methods for efficiently retrieving data Strong Microsoft Excel skills are required including advanced formulas and functions Effective verbal and written communication skills. Ability to communicate the results of analyses clearly and effectively Demonstrated curiosity to dive into available data and enjoy searching for patterns that could indicate new insights Exposure to cloud infrastructure, such as AWS/S3, is a plus Hands-on coding experience is a plus Reasonable accommodation: Dow Jones, Making Careers Newsworthy - We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law. EEO/AA/M/F/Disabled/Vets. Dow Jones is committed to providing reasonable accommodation for qualified individuals with disabilities, in our job application and/or interview process. If you need assistance or accommodation in completing your application, due to a disability, email us at talentresourceteam@dowjones.com. Please put \"Reasonable Accommodation\" in the subject line and provide a brief description of the type of assistance you need. This inbox will not be monitored for application status updates. We recognize that attracting the best talent is key to our strategy and success as a company. As a result, we aim for flexibility in structuring competitive compensation offers to ensure we are able to attract the best candidates. The quoted salary range represents our good faith estimate as to what our ideal candidates are likely to expect, and we tailor our offers within the range based on the selected candidate's experience, industry knowledge, location, technical and communication skills, and other factors that may prove relevant during the interview process. Pay-for-performance is a key element in our strategy to attract, engage, and motivate talented people to do their best work. Similarly to salary, for bonus eligible roles, targets are set based on a variety of factors including competitive market practice. For benefits eligible roles, in addition to cash compensation, the company provides a comprehensive and highly competitive benefits package, with a variety of physical health, retirement and savings, caregiving, emotional wellbeing, transportation, and other benefits, including \"elective\" benefits employees may select to best fit the needs and personal situations of our diverse workforce.. Since 1882, Dow Jones has been finding new ways to bring information to the world’s top business entities. Beginning as a niche news agency in an obscure Wall Street basement, Dow Jones has grown to be a worldwide news and information powerhouse, with prestigious brands including The Wall Street Journal, Dow Jones Newswires, Factiva, Barron’s, MarketWatch and Financial News. This longevity and success is due to a relentless pursuit of accuracy, depth and innovation, enhanced by the wisdom of past experience and a solid grasp on the future ahead. More than its individual brands, Dow Jones is a modern gateway to intelligence, with innovative technology, advanced data feeds, integrated solutions, expert research, award-winning journalism and customizable apps and delivery systems to bring the information that matters most to customers, when and where they need it, every day. Less What they’re looking for You match some qualifications. Graduates by June 2027 Economics major Statistics major General Engineering major Matching is based on your profile. Update profile. About the employer Dow Jones & Co. Journalism, Media & Publishing Follow 1,000-5,000 employees New York City, NY Dow Jones is a global provider of news and business information, delivering content to consumers and organizations around the world across multiple formats, including print, digital, mobile and live events. Dow Jones has produced unrivaled quality content for more than 130 years and today has one of the world’s largest news-gathering operations globally. It is home to leading publications and products including the flagship Wall Street Journal, America’s largest newspaper by paid circulation; Barron’s, MarketWatch, Mansion Global, Financial News, Investor’s Business Daily, Factiva, Dow Jones Risk & Compliance, Dow Jones Newswires, OPIS and Chemical Market Analytics. Dow Jones is a division of News Corp (Nasdaq: NWS, NWSA; ASX: NWS, NWSLV). Learn more Similar Jobs Simon & Schuster Spring 2025 Internship Program Internship New York, NY + 1 ∙ New Johns Hopkins University Applied Physics Laboratory 2025 Internship – Data Science – System Performance Evaluation Internship Laurel, MD ∙ 2wk ago Wiss, Janney, Elstner Associates, Inc. Summer 2025 Internship Internship New York, NY + 22 ∙ 3wk ago Vertiv Data Analyst Internship (Summer 2025) Internship St. Louis, MO ∙ 2wk ago Knights of Columbus - Corporate Careers Summer 2025 Internship Internship New Haven, CT ∙ 1mo ago Under Armour Fashion Summer 2025 Internship, Enterprise Data Management $20–30/hr ∙ Internship ∙ Jun 2–Aug 29 Remote ∙ 3d ago Alumni in similar roles Abhilash Agarwal Follow Komaldeepkaur Narindersingh Bhatia Follow Rishya Parashiva Murthy Follow PS Pratyush Sethi Data scientist Follow Skip to search results Hide job\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from_html_file(file_path):\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(file_path):\n",
    "        return \"File not found.\"\n",
    "\n",
    "    # Open and read the HTML file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Extract text from the parsed HTML\n",
    "    text = soup.get_text(separator=' ', strip=True)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Specify the path to your HTML file in the Downloads folder\n",
    "# Adjust the username and file name as necessary\n",
    "downloads_folder = os.path.expanduser('Downloads')\n",
    "html_file_name = r'c:\\Users\\sabdh\\Downloads\\(18) Postings _ Handshake (9_28_2024 4_19_29 PM).html'  # Replace with your actual HTML file name\n",
    "html_file_path = os.path.join(downloads_folder, html_file_name)\n",
    "\n",
    "# Extract text from the HTML file\n",
    "extracted_text = extract_text_from_html_file(html_file_path)\n",
    "\n",
    "# Print the extracted text\n",
    "print(extracted_text)\n",
    "\n",
    "# # Optional: Write the text to a file\n",
    "# with open('output.txt', 'w', encoding='utf-8') as output_file:\n",
    "#     output_file.write(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nova Southeastern University, Davie FL\n",
      " B.S. in Computer Science, Expected May 2010\n",
      " Minors in Mathematics and Physics GPA: 3.75 Honors: Dean's List\n",
      "Relevant Courses:\n",
      " Human-Computer Interaction, Artificial Intelligence, 3D Animation, Logic Programming,\n",
      "Quantum Mechanics, Theory of Computation, Machine Learning, Computer Graphics\n",
      "SKILLS / STRENGTHS\n",
      " Programming languages: Perl, Java, C++, HTML, PHP, MySQL, Scheme, MatLab\n",
      " Software: Microsoft Office, Adobe Photoshop and Dreamweaver, 3ds Max\n",
      " Operating Systems: Windows (95, 98, 2000, XP, Vista), Mac OS, Linux\n",
      " Professional: Self-motivated, creative thinker; detail-oriented; excellent time management\n",
      "skills\n",
      "EXPERIENCE\n",
      "ABC Research, Boca Raton FL, May 2008 – Sept 2008\n",
      "Collaborative User Experience Group Intern\n",
      " Developed wikis, blogs, and social networks with a team of computer and social scientists\n",
      " Contributed technical support to development of groundbreaking networking software to be\n",
      "showcased in forthcoming industry publication\n",
      "Library Application Services, NSU, Davie FL, May 2007 - Present\n",
      "Student Web Developer\n",
      " Develop and maintain individualized websites for a range of divisions across the university\n",
      " Assist in the technical administration of the campus intranet and calendar systems\n",
      "Computer Science Departments, NSU, Davie FL, Sept 2007 - May 2008\n",
      "Teaching Assistant\n",
      " Gave weekly lectures to students enrolled in advanced programming language course and\n",
      "introductory physics course\n",
      " Explained complex concepts in small group setting; grade assignments and examinations\n",
      " Held office hours for individual student discussion\n",
      "YMCA, Fort Lauderdale FL, Jan 2005 – August 2007\n",
      "Computer teacher\n",
      " Taught basic computer skills to teenage and elderly town residents\n",
      "ACTIVITIES\n",
      " Tutored elementary school children in math and science\n",
      "Freelance Music Teacher, Fort Lauderdale FL, 2005 - Present\n",
      " Give guitar and piano lessons to high school and college students\n",
      " Prepare students for recitals and accompany them during performances\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "\n",
    "def extract_text_after_subheading(pdf_path, subheading):\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(pdf_path):\n",
    "        return \"File not found.\"\n",
    "\n",
    "    # Open the PDF file and extract text\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = ''\n",
    "        capturing = False  # Flag to indicate if we are capturing text\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:  # Check if there is text on the page\n",
    "                for line in page_text.split('\\n'):\n",
    "                    # Check if the line contains the subheading\n",
    "                    if subheading.lower() in line.lower():\n",
    "                        capturing = True  # Start capturing after the subheading\n",
    "                        continue\n",
    "                    if capturing:\n",
    "                        text += line + '\\n'  # Capture all subsequent lines\n",
    "\n",
    "    return text.strip()  # Return the extracted text without leading/trailing spaces\n",
    "\n",
    "# Specify the path to your PDF file in the Downloads folder\n",
    "downloads_folder = os.path.expanduser('Downloads')\n",
    "pdf_file_name = r'c:\\Users\\sabdh\\Downloads\\RS.pdf'  # Replace with your actual PDF file name\n",
    "pdf_file_path = os.path.join(downloads_folder, pdf_file_name)\n",
    "\n",
    "# Specify the subheading from which to start extracting text\n",
    "subheading = 'Education'  # Replace with your desired subheading\n",
    "\n",
    "# Extract text from the PDF file after the specified subheading\n",
    "extracted_text_2 = extract_text_after_subheading(pdf_file_path, subheading)\n",
    "\n",
    "# Print the extracted text\n",
    "print(extracted_text_2)\n",
    "\n",
    "# Optional: Write the text to a file\n",
    "# output_file_path = 'extracted_resume_text_after_subheading.txt'\n",
    "# with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "#     output_file.write(extracted_text)\n",
    "\n",
    "# print(f\"Extracted text has been saved to '{output_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Response: \n",
      "The skills required for the 'Data Analyst Intern' job at Dow Jones & Co. include:\n",
      "\n",
      "1. Completed at least 2 years toward a Bachelor’s degree in a quantitative subject (Statistics, Engineering, Economics, etc.)\n",
      "2. Exposure to data analysis and problem solving with large amounts of diverse data\n",
      "3. Basic fluency in SQL, Python or knowledge of relational databases and methods for efficiently retrieving data\n",
      "4. Strong Microsoft Excel skills including advanced formulas and functions\n",
      "5. Effective verbal and written communication skills\n",
      "6. Demonstrated curiosity to dive into available data and enjoy searching for patterns that could indicate new insights\n",
      "7. Exposure to cloud infrastructure, such as AWS/S3, is a plus\n",
      "8. Hands-on coding experience is a plus\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "jd_text=\" \"\n",
    "# Function to generate response using OpenAI's GPT-4\n",
    "def generate_response(prompt, api_key):\n",
    "    openai.api_key = api_key\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150,\n",
    "        )\n",
    "        \n",
    "        # Extract and return the text response from the API\n",
    "        return response['choices'][0]['message']['content']\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ask for user input\n",
    "    user_input =\"job description \" + extracted_text + \"find the skills required from it..\"\n",
    "    \n",
    "    # Replace with your OpenAI API key\n",
    "    api_key = \"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\"\n",
    "    \n",
    "    # Generate and print the response\n",
    "    response_text_jd = generate_response(user_input, api_key)\n",
    "    jd_text=response_text_jd\n",
    "    print(\"\\nGenerated Response: \")\n",
    "    print(response_text_jd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Response: \n",
      "Based on the resume provided, there are a few skills required by the job description for a 'Data Analyst Intern' at Dow Jones & Co. that are missing. These include:\n",
      "\n",
      "1. Basic fluency in SQL, Python: The resume doesn't mention any experience with these programming languages. However, the candidate does have experience with Perl, Java, C++, HTML, PHP, MySQL, Scheme, and MatLab.\n",
      "   - SQL Certification: [SQL for Data Science by University of California](https://www.coursera.org/learn/sql-for-data-science)\n",
      "   - Python Certification: [Python for Data Science and Machine Learning Bootcamp](https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Function to generate response using OpenAI's GPT-4\n",
    "def generate_response(prompt, api_key):\n",
    "    openai.api_key = api_key\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150,\n",
    "        )\n",
    "        \n",
    "        # Extract and return the text response from the API\n",
    "        return response['choices'][0]['message']['content']\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ask for user input\n",
    "    user_input =\"job description \"+ jd_text + \"resume\" + extracted_text_2 + \"find the certifications (include links) of the missing skills from resume required by job description..\"\n",
    "    \n",
    "    # Replace with your OpenAI API key\n",
    "    api_key = \"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\"\n",
    "    \n",
    "    # Generate and print the response\n",
    "    response_text_final = generate_response(user_input, api_key)\n",
    "    print(\"\\nGenerated Response: \")\n",
    "    print(response_text_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Generated Response: \n",
    "Based on the resume provided, there are a few skills required by the job description for a 'Data Analyst Intern' at Dow Jones & Co. that are missing. These include:\n",
    "\n",
    "1. Basic fluency in SQL, Python: The resume doesn't mention any experience with these programming languages. However, the candidate does have experience with Perl, Java, C++, HTML, PHP, MySQL, Scheme, and MatLab.\n",
    "   - SQL Certification: [SQL for Data Science by University of California](https://www.coursera.org/learn/sql-for-data-science)\n",
    "   - Python Certification: [Python for Data Science and Machine Learning Bootcamp](https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Response: \n",
      "1. Data Analysis: [Link to Course](https://www.coursera.org/learn/data-analysis-with-python)\n",
      "2. SQL: [Link to Course](https://www.coursera.org/learn/sql-data-science)\n",
      "3. Adobe, Tableau, Google Analytics: [Link to Course](https://www.udemy.com/course/the-complete-tableau-bootcamp-for-aspiring-data-scientists/)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "courses=\"\"\n",
    "# Function to generate response using OpenAI's GPT-4\n",
    "def generate_response(prompt, api_key):\n",
    "    openai.api_key = api_key\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3, # \n",
    "            max_tokens=150,# if we increase the max_tokens it will complete answers\n",
    "        )\n",
    "        \n",
    "        # Extract and return the text response from the API\n",
    "        return response['choices'][0]['message']['content']\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ask for user input\n",
    "    user_input =\"job description\" + extracted_text + \" \" + \"Resume\" + extracted_text_2 + \"find 3 courses that I am missing in my job resume and are required by the job description, give me the course name and link,don't print anything else..\"\n",
    "    \n",
    "    # Replace with your OpenAI API key\n",
    "    api_key = \"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\"\n",
    "    \n",
    "    # Generate and print the response\n",
    "    response_text = generate_response(user_input, api_key)\n",
    "    courses=response_text\n",
    "    print(\"\\nGenerated Response: \")\n",
    "    print(response_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Generated Response: \n",
    "1. Data Analysis: [Link](https://www.coursera.org/courses?query=data%20analysis)\n",
    "2. SQL: [Link](https://www.coursera.org/courses?query=sql)\n",
    "3. Cloud Infrastructure (AWS/S3): [Link](https://www.coursera.org/courses?query=cloud%20infrastructure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Response: \n",
      "Roadmap to learn Data Analysis, SQL, and Cloud Infrastructure:\n",
      "\n",
      "**1. Start with Data Analysis:**\n",
      "   - First, it is necessary to establish a foundation in statistics as it is vital for data analysis. Look for courses that cover statistical basics such as mean, median, mode, variance, standard deviation, and probability. \n",
      "   - Next, learn about data visualization. You should know how to create and interpret data visuals like bar graphs, pie charts, heat maps, etc. \n",
      "   - After that, you can start learning about data manipulation and cleaning. This will involve understanding how to handle missing or inconsistent data, and how to transform data to make it suitable for analysis.\n",
      "   - Finally, learn about predictive analytics. This will involve learning about regression analysis, machine learning, and how to build predictive models.\n",
      "\n",
      "**2. Move on to SQL:**\n",
      "   - Start with an introduction to databases. Understand what databases are, how they work, and why they are important. \n",
      "   - Learn the basics of SQL, including how to create, read, update, and delete data from a database.\n",
      "   - Next, learn about more complex SQL queries. This will include learning about joins, subqueries, and aggregate functions.\n",
      "   - Finally, learn about database design. This will involve learning how to create and maintain efficient and effective databases.\n",
      "\n",
      "**3. Finish with Cloud Infrastructure (AWS/S3):**\n",
      "   - Start with an introduction to cloud computing. Understand what it is, why it's important, and the different types of cloud computing (IaaS, PaaS, SaaS).\n",
      "   - Learn about AWS and its core services, including EC2, S3, and IAM.\n",
      "   - Next, learn about AWS architecture and how to design and deploy applications on AWS.\n",
      "   - Learn about AWS security and how to protect your data and applications.\n",
      "   - Finally, learn about AWS cost management and how to manage and optimize AWS costs.\n",
      "\n",
      "Remember, it can be helpful to do projects or exercises that allow you to apply what you've learned in each of these areas. This will not only help to reinforce your learning but also give you practical experience that can be valuable in a real-world setting. Also, it's important to note that this is a general roadmap and the sequence can be adjusted based on your existing knowledge and specific learning goals.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Function to generate response using OpenAI's GPT-4\n",
    "def generate_response(prompt, api_key):\n",
    "    openai.api_key = api_key\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=550,\n",
    "        )\n",
    "        \n",
    "        # Extract and return the text response from the API\n",
    "        return response['choices'][0]['message']['content']\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ask for user input\n",
    "    user_input =\"give me a roadmap to learn these courses\" +  courses \n",
    "    # Replace with your OpenAI API key\n",
    "    api_key = \"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\"\n",
    "    \n",
    "    # Generate and print the response\n",
    "    response_text = generate_response(user_input, api_key)\n",
    "    print(\"\\nGenerated Response: \")\n",
    "    print(response_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
